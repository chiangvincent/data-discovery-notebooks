{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import ftplib\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference docs for the format and organization of ADP VIIRS data \n",
    "# https://www.star.nesdis.noaa.gov/smcd/spb/aq/AerosolWatch/docs/EPS_ADP_Users_Guide_V1_Sep2020.pdf\n",
    "\n",
    "# Bounding box values for CA\n",
    "# https://anthonylouisdagostino.com/bounding-boxes-for-all-us-states/\n",
    "# original bounding box (lat, lon)\n",
    "UPPER_RIGHT = (43, -114)\n",
    "LOWER_LEFT = (32, -125)\n",
    "\n",
    "# Need to extend the bounding box region, since the swath width of VIIRS granule is 3060 km.\n",
    "LAT_OFFSET = 10 \n",
    "LON_OFFSET = 20\n",
    "\n",
    "MAXLAT = UPPER_RIGHT[0] + LAT_OFFSET\n",
    "MAXLON = UPPER_RIGHT[1] + LON_OFFSET\n",
    "MINLAT = LOWER_LEFT[0] - LAT_OFFSET\n",
    "MINLON = LOWER_LEFT[1] - LON_OFFSET\n",
    "\n",
    "# API URL for OrbNav API\n",
    "ORBNAV_API_URL = \"https://sips.ssec.wisc.edu/orbnav/api/v1/boxtimes.json?\"\n",
    "\n",
    "# Satellite IDs used in the OrbNav API\n",
    "SATELLITE_ID_MAP = {\n",
    "    \"NOAA_20\": 43013,\n",
    "    \"SNPP\": 37849\n",
    "}\n",
    "\n",
    "# FTP hostname \n",
    "FTP_HOSTNAME = \"ftp.star.nesdis.noaa.gov\"\n",
    "\n",
    "# Filepath on the FTP server for the two VIIRS satellites\n",
    "SATELLITE_FTP_PATH_MAP = {\n",
    "    \"NOAA_20\": \"/pub/smcd/hzhang/VIIRS_EPS_NRT/ADP_N20/CONUS/\",\n",
    "    \"SNPP\": \"/pub/smcd/hzhang/VIIRS_EPS_NRT/ADP/CONUS/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_overpass_times(satellite: str, date: datetime = datetime.utcnow()):\n",
    "    # Returns a list of (start, end) datetime objects for a satellite using the OrbNav API\n",
    "    satellite_id = SATELLITE_ID_MAP[satellite]\n",
    "    ur = str(MAXLAT) + \", \" + str(MAXLON)\n",
    "    ll = str(MINLAT) + \", \" + str(MINLON)\n",
    "    args = {\n",
    "        \"sat\": satellite_id,\n",
    "        \"start\": get_utc_start(date),\n",
    "        \"end\": get_utc_end(date),\n",
    "        \"ll\": ll,\n",
    "        \"ur\": ur\n",
    "    }\n",
    "    request_url = ORBNAV_API_URL + urllib.parse.urlencode(args)\n",
    "    resp = requests.get(request_url)\n",
    "    if resp.status_code != 200:\n",
    "        return\n",
    "    return process_resp(resp.json())\n",
    "\n",
    "def get_utc_start(curr_date: datetime):\n",
    "    # return midnight timestamp of  date\n",
    "    midnight = curr_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    return midnight.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "def get_utc_end(curr_date: datetime):\n",
    "    # return latest timestamp of  date\n",
    "    midnight = curr_date.replace(hour=23, minute=59, second=59, microsecond=0)\n",
    "    return midnight.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "def process_resp(overpass_times_json):\n",
    "    # processes the request and creates a list of (start, end) datetime objects that correspond to when the satellite\n",
    "    # was in the bounding box\n",
    "    overpass_times = []\n",
    "    for data in overpass_times_json[\"data\"]:\n",
    "        start_timestamp = data[0][0]\n",
    "        end_timestamp = data[1][0]\n",
    "        start = datetime.strptime(start_timestamp, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        end = datetime.strptime(end_timestamp, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        overpass_times.append([start, end])\n",
    "    return overpass_times\n",
    "\n",
    "def is_valid_granule(filename, overpass_times):\n",
    "    observation_timestamp = get_observation_timestamp(filename)\n",
    "    for overpass in overpass_times:\n",
    "        start, end = overpass\n",
    "        if start <= observation_timestamp <= end: \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_observation_timestamp(filename):\n",
    "    # Returns a datetime object corresponding to the file observation time\n",
    "    observation_timestamp = filename.split(\"_\")[3][1:]\n",
    "    observation_datetime = datetime.strptime(observation_timestamp, '%Y%m%d%H%M%S%f').replace(microsecond=0)\n",
    "    return observation_datetime\n",
    "\n",
    "\n",
    "def download_granules(satellite, download_dir = \"\", date: datetime = datetime.utcnow()):\n",
    "    # Downloads the granules from the FTP server for a given satellite for timestamps covering California\n",
    "    ftp_path = SATELLITE_FTP_PATH_MAP[satellite]\n",
    "    ftp_path += date.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    overpass_times = fetch_overpass_times(satellite, date)\n",
    "    \n",
    "    with ftplib.FTP(FTP_HOSTNAME) as ftp:\n",
    "        try:\n",
    "            ftp.login()\n",
    "            ftp.cwd(ftp_path)\n",
    "            files = []\n",
    "            ftp.dir(files.append)\n",
    "            for file in files:\n",
    "                filename = file.split(\" \")[-1]\n",
    "                if (is_valid_granule(filename, overpass_times)):\n",
    "                    with open(download_dir + filename, 'wb') as f:\n",
    "                        print(\"Downloading %s...\" % filename)\n",
    "                        ftp.retrbinary('RETR ' + filename, f.write)\n",
    "        except ftplib.all_errors as e:\n",
    "            print('FTP error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nov12 = datetime(2020, 11, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[datetime.datetime(2020, 11, 12, 7, 58, 18),\n",
       "  datetime.datetime(2020, 11, 12, 7, 59, 41)],\n",
       " [datetime.datetime(2020, 11, 12, 9, 32, 18),\n",
       "  datetime.datetime(2020, 11, 12, 9, 41, 11)],\n",
       " [datetime.datetime(2020, 11, 12, 11, 13, 48),\n",
       "  datetime.datetime(2020, 11, 12, 11, 21, 34)],\n",
       " [datetime.datetime(2020, 11, 12, 19, 15, 45),\n",
       "  datetime.datetime(2020, 11, 12, 19, 20, 52)],\n",
       " [datetime.datetime(2020, 11, 12, 20, 53, 28),\n",
       "  datetime.datetime(2020, 11, 12, 21, 2, 22)],\n",
       " [datetime.datetime(2020, 11, 12, 22, 34, 58),\n",
       "  datetime.datetime(2020, 11, 12, 22, 38, 59)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_overpass_times(\"NOAA_20\", nov12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading JRR-ADP_v2r3_j01_s202011121916319_e202011121917546_c202011121944260.nc...\n",
      "Downloading JRR-ADP_v2r3_j01_s202011121917558_e202011121919203_c202011121945070.nc...\n",
      "Downloading JRR-ADP_v2r3_j01_s202011121919216_e202011121920461_c202011121945030.nc...\n",
      "Downloading JRR-ADP_v2r3_j01_s202011121920473_e202011121922119_c202011121945350.nc...\n",
      "Downloading JRR-ADP_v2r3_j01_s202011122054405_e202011122056050_c202011122127020.nc...\n",
      "Downloading JRR-ADP_v2r3_j01_s202011122056062_e202011122057289_c202011122126560.nc...\n",
      "Downloading JRR-ADP_v2r3_j01_s202011122057302_e202011122058547_c202011122127190.nc...\n",
      "Downloading JRR-ADP_v2r3_j01_s202011122058559_e202011122100205_c202011122137340.nc...\n",
      "Downloading JRR-ADP_v2r3_j01_s202011122100217_e202011122101462_c202011122137470.nc...\n",
      "Downloading JRR-ADP_v2r3_j01_s202011122101474_e202011122103102_c202011122137180.nc...\n"
     ]
    }
   ],
   "source": [
    "download_granules(\"NOAA_20\", \"\",  nov12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_overpass_times(\"SNPP\", nov12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_granules(\"SNPP\", \"\",  nov12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
